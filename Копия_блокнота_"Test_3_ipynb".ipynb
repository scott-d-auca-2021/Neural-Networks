{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scott-d-auca-2021/Neural-Networks/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22Test_3_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12e3e615",
      "metadata": {
        "id": "12e3e615"
      },
      "source": [
        "## Task 1 (10 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab52aedf",
      "metadata": {
        "id": "ab52aedf"
      },
      "source": [
        "Select padding sizes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be5cc335",
      "metadata": {
        "id": "be5cc335",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff381bad-347c-4bb1-d971-396da94f641e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 10, 8, 16])\n",
            "torch.Size([4, 10, 8, 16])\n",
            "torch.Size([4, 10, 8, 16])\n",
            "torch.Size([4, 10, 8, 16])\n",
            "torch.Size([4, 10, 8, 16])\n",
            "torch.Size([4, 10, 22, 30])\n",
            "torch.Size([4, 10, 7, 15])\n",
            "torch.Size([4, 10, 9, 17])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "N = 4\n",
        "C = 3\n",
        "C_out = 10\n",
        "H = 8\n",
        "W = 16\n",
        "\n",
        "x = torch.ones((N, C, H, W))\n",
        "\n",
        "# torch.Size([4, 10, 8, 16])\n",
        "out1 = torch.nn.Conv2d(C, C_out, kernel_size=(3, 3), padding= 2 // 2)(x)\n",
        "print(out1.shape) # for self-test\n",
        "\n",
        "# torch.Size([4, 10, 8, 16])\n",
        "out2 = torch.nn.Conv2d(C, C_out, kernel_size=(5, 5), padding= 4 // 2 )(x)\n",
        "print(out2.shape) # for self-test\n",
        "\n",
        "# torch.Size([4, 10, 8, 16])\n",
        "out3 = torch.nn.Conv2d(C, C_out, kernel_size=(7, 7), padding= 6 // 2)(x)\n",
        "print(out3.shape) # for self-test\n",
        "\n",
        "# torch.Size([4, 10, 8, 16])\n",
        "out4 = torch.nn.Conv2d(C, C_out, kernel_size=(9, 9), padding= 8 // 2)(x)\n",
        "print(out4.shape) # for self-test\n",
        "\n",
        "# torch.Size([4, 10, 8, 16])\n",
        "out5 = torch.nn.Conv2d(C, C_out, kernel_size=(3, 5), padding= (2 // 2, 4 // 2))(x)\n",
        "print(out5.shape) # for self-test\n",
        "\n",
        "# torch.Size([4, 10, 22, 30])\n",
        "# тут использовала другую формулу: ((output_height - 1) * stride_h + kernel_size_h - input_height) // 2\n",
        "out6 = torch.nn.Conv2d(C, C_out, kernel_size=(3, 3), padding= ((22 - 1) * 1 + 3 - 8) // 2)(x)\n",
        "print(out6.shape) # for self-test\n",
        "\n",
        "# torch.Size([4, 10, 7, 15])\n",
        "out7 = torch.nn.Conv2d(C, C_out, kernel_size=(4, 4), padding=3 // 2)(x)\n",
        "print(out7.shape) # for self-test\n",
        "\n",
        "# torch.Size([4, 10, 9, 17])\n",
        "# тут тоже другая формула\n",
        "out8 = torch.nn.Conv2d(C, C_out, kernel_size=(2, 2), padding= ((9 - 1) * 1 + 2 - 8) // 2)(x)\n",
        "print(out8.shape) # for self-test\n",
        "# вроде, все совпало"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e0e467e",
      "metadata": {
        "id": "8e0e467e"
      },
      "source": [
        "## Task 2 (40 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "329c2efa",
      "metadata": {
        "id": "329c2efa"
      },
      "source": [
        "Develop an architecture according to the data from the article.\n",
        "To test the functionality, test your architecture on any suitable data set.\n",
        "\n",
        "### Architectural Design Strategies\n",
        "**Strategy 1.** Replace 3×3 filters with 1×1 filters\n",
        "Given a budget of a certain number of convolution filters, we can choose to make the majority of these filters 1×1, since a 1×1 filter has 9× fewer parameters than a 3×3 filter.\n",
        "\n",
        "**Strategy 2.** Decrease the number of input channels to 3×3 filters\n",
        "Consider a convolution layer that is comprised entirely of 3×3 filters. The total quantity of parameters in this layer is:\n",
        "(number of input channels) × (number of filters) × (3×3)\n",
        "We can decrease the number of input channels to 3×3 filters using squeeze layers, mentioned in the next section.\n",
        "\n",
        "**Strategy 3.** Downsample late in the network so that convolution layers have large activation maps\n",
        "The intuition is that large activation maps (due to delayed downsampling) can lead to higher classification accuracy.\n",
        "\n",
        "### Fire Module\n",
        "![](https://miro.medium.com/v2/resize:fit:930/format:webp/1*ONk0HfLLjDcUhUjuu8iq1w.png)\n",
        "A Fire module is comprised of: a squeeze convolution layer (which has only 1×1 filters), feeding into an expand layer that has a mix of 1×1 and 3×3 convolution filters.\n",
        "\n",
        "There are three tunable dimensions (hyperparameters) in a Fire module: s1×1, e1×1, and e3×3.\n",
        "\n",
        "s1×1: The number of 1×1 in squeeze layer.\n",
        "\n",
        "e1×1 and e3×3: The number of 1×1 and 3×3 in expand layer.\n",
        "\n",
        "When we use Fire modules we set s1×1 to be less than (e1×1 + e3×3), so the squeeze layer helps to limit the number of input channels to the 3×3 filters, as per Strategy 2 in previous section.\n",
        "To me, it is quite a like of Inception Module.\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y87bqk95D-IndWdHM_K9-g.png)\n",
        "![](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*XQGAKZb8kjoF_1lSXeIQxg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b02f06c6",
      "metadata": {
        "id": "b02f06c6"
      },
      "source": [
        "## Step 0. Data preparation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "7209e6d0",
      "metadata": {
        "id": "7209e6d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b274e935-8fe6-4bf4-8b8d-a1498aefa16d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:75: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:65: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:80: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        }
      ],
      "source": [
        "# я не смогла импортировать stanford cars, поэтому, чтобы хоть что-то было, использовала dataset из классной работы\n",
        "\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "import torchvision.datasets\n",
        "\n",
        "MNIST_train = torchvision.datasets.MNIST('./', download=True, train=True)\n",
        "MNIST_test = torchvision.datasets.MNIST('./', download=True, train=False)\n",
        "\n",
        "X_train = MNIST_train.train_data\n",
        "y_train = MNIST_train.train_labels\n",
        "X_test = MNIST_test.test_data\n",
        "y_test = MNIST_test.test_labels\n",
        "\n",
        "X_train = X_train.unsqueeze(1).float()\n",
        "X_test = X_test.unsqueeze(1).float()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74a4e84f",
      "metadata": {
        "id": "74a4e84f"
      },
      "source": [
        "## Step 1. Neural network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "a601be60",
      "metadata": {
        "id": "a601be60"
      },
      "outputs": [],
      "source": [
        "# я пыталась найти документацию по Fire и вышел вот такой код в интрнете для архитектуры.\n",
        "# со своими знаниями я бы может быть немного приблизалсь к такому, но мой код был бы далек от рабочего кода\n",
        "\n",
        "class Fire(torch.nn.Module):\n",
        "    def __init__(self, inplanes, squeeze_planes, expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = torch.nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = torch.nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = torch.nn.Conv2d(squeeze_planes, expand1x1_planes, kernel_size=1)\n",
        "        self.expand1x1_activation = torch.nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = torch.nn.Conv2d(squeeze_planes, expand3x3_planes, kernel_size=3, padding=1)\n",
        "        self.expand3x3_activation = torch.nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "class Squeeze(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, version='1_0', num_classes=10):\n",
        "        super(Squeeze, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.features = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 96, kernel_size=7, stride=2),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "            Fire(96, 16, 64, 64),\n",
        "            Fire(128, 16, 64, 64),\n",
        "            Fire(128, 32, 128, 128),\n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "            Fire(256, 32, 128, 128),\n",
        "            Fire(256, 48, 192, 192),\n",
        "            Fire(384, 48, 192, 192),\n",
        "            Fire(384, 64, 256, 256),\n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "            Fire(512, 64, 256, 256),\n",
        "            )\n",
        "\n",
        "        final_conv = torch.nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = torch.nn.Sequential(\n",
        "            torch.nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return torch.flatten(x, 1)\n",
        "\n",
        "squeeze = Squeeze()\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "squeeze = squeeze.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6947b78d",
      "metadata": {
        "id": "6947b78d"
      },
      "source": [
        "## Step 2.  Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "dbd1515b",
      "metadata": {
        "id": "dbd1515b"
      },
      "outputs": [],
      "source": [
        "loss =torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "098332de",
      "metadata": {
        "id": "098332de"
      },
      "source": [
        "## Step 3. Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "bc70ea1f",
      "metadata": {
        "id": "bc70ea1f"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(squeeze.parameters(), lr=1.0e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20bbcf0c",
      "metadata": {
        "id": "20bbcf0c"
      },
      "source": [
        "## Step 4. Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22aa87ed",
      "metadata": {
        "id": "22aa87ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8053ec1b-8770-4015-e66e-b8335a4ea924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0980)\n",
            "tensor(0.0980)\n",
            "tensor(0.0980)\n",
            "tensor(0.0980)\n",
            "tensor(0.0980)\n"
          ]
        }
      ],
      "source": [
        "# я взяла train loop из прошлой классной работы\n",
        "batch_size = 10\n",
        "\n",
        "test_accuracy_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "X_test = X_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "for epoch in range(10):\n",
        "    order = np.random.permutation(len(X_train))\n",
        "    for start_index in range(0, len(X_train), batch_size):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch_indexes = order[start_index:start_index+batch_size]\n",
        "\n",
        "        X_batch = X_train[batch_indexes].to(device)\n",
        "        y_batch = y_train[batch_indexes].to(device)\n",
        "\n",
        "        preds = squeeze.forward(X_batch)\n",
        "\n",
        "        loss_value = loss(preds, y_batch)\n",
        "        loss_value.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    test_preds = squeeze.forward(X_test)\n",
        "    test_loss_history.append(loss(test_preds, y_test).data.cpu())\n",
        "\n",
        "    accuracy = (test_preds.argmax(dim=1) == y_test).float().mean().data.cpu()\n",
        "    test_accuracy_history.append(accuracy)\n",
        "\n",
        "    print(accuracy)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}